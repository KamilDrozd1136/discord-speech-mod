"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.resolveSpeechWithAzureSpeechToText = void 0;
const sdk = require("microsoft-cognitiveservices-speech-sdk");
const fs = require('fs');
const readline = require('readline');

async function addPhrasesFromFile(filePath, phraseList) {
    const fileStream = fs.createReadStream(filePath);

    const rl = readline.createInterface({
        input: fileStream,
        crlfDelay: Infinity
    });

    for await (const line of rl) {
        phraseList.addPhrase(line);
    }
}

function getAzureRequestOptions(options) {
    const speechConfig = sdk.SpeechConfig.fromSubscription(options.key, options.region);
    if (options.lang) {
        speechConfig.speechRecognitionLanguage = options.lang;
        speechConfig.setProfanity(sdk.ProfanityOption.Raw);
    }
    console.log(options.lang);
    return speechConfig;
}
/**
 * Performs speech recognition using the Azure Speech to Text API 
 * @param audioBuffer PCM mono audio with 16kHz
 * @param options
 * @returns Recognized text from speech
 */
function resolveSpeechWithAzureSpeechToText(audioBuffer, options) {
    const pushStream = sdk.AudioInputStream.createPushStream();

    // Write your PCM data into the push stream
    pushStream.write(audioBuffer);

    // Close the push stream
    pushStream.close();

    const speechConfig = getAzureRequestOptions(options);
    const audioConfig = sdk.AudioConfig.fromStreamInput(pushStream);
    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

    const phraseList = sdk.PhraseListGrammar.fromRecognizer(recognizer);

    // Add slang phrases that might not be recognized correctly, up to 500 phrases
    addPhrasesFromFile('./phrases.txt', phraseList);
 
    return new Promise((resolve, reject) => {
        recognizer.recognizeOnceAsync(
            (result) => {
                recognizer.close();
                resolve(result.privText);
            },
            (err) => {
                console.log('Recognition failed');
                recognizer.close();
                reject(err);
                console.log(err);
            }
        );
    });
}

module.exports.resolveSpeechWithAzureSpeechToText = resolveSpeechWithAzureSpeechToText;